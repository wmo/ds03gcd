# Quick start

- Clone this repository
- Put the data-file in the same directory as "run_analysis.R" 
- startup R and run: `source "run_analysis.R"`
- after a while of huffing and puffing, you get the final tidy dataset in dataframe `df`

The dataframe will look like this, when viewed in RStudio: 
![](sample_snap.png)

It has these dimensions: 180 observations of 75 variables.

See [codebook](codebook.md) for description of the datafields.

## Extras

The requested dataframe `df` contains the final, tidy data-set, but there are some extra dataframes created in the process, which may be of good use:

- `dfc` : the comprehensive dataframe, contains all columns, all data 
- `dfs` : the selective dataframe, is the same as `dfc` but with the feature columns whitled down to only *std* and *mean* 
- `dfnrw` : the narrow dataframe, which is a molten form of `dfs`, and which formed the basis to create the final `df` from.

For playing around with a limited number of rows of data, change the variable `max_observations` for example to '125' in the script. This gives a faster load time, and it also is faster to do certain transforms. 


# Preconditions

You should have R installed plus following packages:

    - plyr
    - reshape2

The datafile has should have these files (subdirectory in which these are is of no importance) 

- features.txt 
- subject_test.txt 
- y_test.txt 
- X_test.txt 
- subject_train.txt 
- y_train.txt 
- X_train.txt 


## Quick-fix to common problems

In case the script cannot find the dataset file, then either:

- rename the file to "UCI HAR Dataset.zip" (warning: contains whitespaces), or
- edit the `run_analysis.R` script, and change the variable `zipfilename` to the exact filename

In case you run into this error: 'could not find function "mapvalues"', then install package `plyr`

In case you encounter this error: 'could not find function "melt"', then install package `reshape2`


# More detail 

The original tasks read as follows: You should create one R script called `run_analysis.R` that does the following.

1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement.
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive variable names.
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.


## Item 1: Merges the training and the test sets to create one data set. 

Result in : *dfc*  (the 'comprehensive' dataframe) 

This dataframe contains each and every record that is in the files, and captures all the information. 


## Item 2: Extracts only the measurements on the mean and standard deviation for each measurement.

Result in *dfs* (the 'selective' dataframe), which is basically the same as dfc, except has a lot less feature columns


## Item 3: Uses descriptive activity names to name the activities in the data set

The activity column contains the activity name. This column was already added in the first step, ie it is present in dataframes `dfc` and `dfs.


## Item 4: Appropriately labels the data set with descriptive variable names.

Also part of building `dfc`, the comprehensive dataframe, was to give the columns the correct names. 


## Item 5: from the data set in step 4, creates a second, independent tidy data set set with the average of each variable for each activity and each subject.

The result ends up in dataframe `df`.  
This result has been generated by first 'melting' the `dfs` dataframe to a narrow representation (dfnrw), and then splitting/applying/composing with plyr's ddply() and reshape2's dcast() functions. 





